# ğŸ§ª Taller - Reconocimiento de Acciones Simples con DetecciÃ³n de Postura

## ğŸ“… Fecha

`2025-06-24` â€“ Fecha de entrega

---

## ğŸ” Objetivo del taller

Implementar el reconocimiento de **acciones simples** (como sentarse, levantar brazos o caminar frente a cÃ¡mara) usando **MediaPipe Pose** para detectar la postura corporal. El objetivo es utilizar puntos clave del cuerpo (landmarks) para interpretar la acciÃ³n y responder visual o sonoramente.

---

## ğŸ§  Conceptos Aprendidos

Lista los principales conceptos aplicados:

- [x] DetecciÃ³n de pose humana con `mediapipe`
- [x] Procesamiento de video en tiempo real con `opencv`
- [x] ExtracciÃ³n y anÃ¡lisis de landmarks corporales
- [x] LÃ³gica condicional para clasificaciÃ³n de posturas
- [x] VisualizaciÃ³n y anotaciÃ³n de resultados en la imagen

---

## ğŸ”§ Herramientas y Entornos

- Python 3.9.7
- MediaPipe
- OpenCV
- NumPy
- Visual Studio Code

---

## ğŸ“ Estructura del Proyecto

```
2025-06-24_taller_reconocimiento_postura_mediapipe/
â”œâ”€â”€ python/
â”‚   â”œâ”€â”€ .python-version
â”‚   â””â”€â”€ solucion.py
â”œâ”€â”€ resultado/
â”‚   â””â”€â”€ python_EHUY6fzo3E.gif
â”œâ”€â”€ README.md
```

---

## ğŸ§ª ImplementaciÃ³n

### ğŸ”¹ Etapas realizadas

1. InicializaciÃ³n de la captura de video con OpenCV.
2. ConfiguraciÃ³n del detector de pose de MediaPipe.
3. Procesamiento de cada frame: conversiÃ³n a RGB y detecciÃ³n de landmarks.
4. ExtracciÃ³n de puntos clave relevantes (hombros, muÃ±ecas, caderas, rodillas).
5. ImplementaciÃ³n de lÃ³gica para clasificar acciones/posturas:
   - Levantando brazos
   - Sentado
   - Caminando
   - AcciÃ³n no reconocida
6. VisualizaciÃ³n de los landmarks y la acciÃ³n detectada sobre el video en tiempo real.
7. FinalizaciÃ³n segura de la captura y cierre de ventanas.

### ğŸ”¹ CÃ³digo relevante

```python
import cv2
import mediapipe as mp
import numpy as np

mp_pose = mp.solutions.pose
pose = mp_pose.Pose()
mp_drawing = mp.solutions.drawing_utils

cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("No se pudo leer el frame.")
        break

    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(frame_rgb)

    if results.pose_landmarks:
        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        landmarks = results.pose_landmarks.landmark
        left_shoulder = landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER]
        right_shoulder = landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER]
        left_wrist = landmarks[mp_pose.PoseLandmark.LEFT_WRIST]
        right_wrist = landmarks[mp_pose.PoseLandmark.RIGHT_WRIST]
        left_hip = landmarks[mp_pose.PoseLandmark.LEFT_HIP]
        right_hip = landmarks[mp_pose.PoseLandmark.RIGHT_HIP]
        left_knee = landmarks[mp_pose.PoseLandmark.LEFT_KNEE]
        right_knee = landmarks[mp_pose.PoseLandmark.RIGHT_KNEE]

        if left_wrist.y < left_shoulder.y and right_wrist.y < right_shoulder.y:
            action = "Levantando brazos"
        elif left_hip.y > left_knee.y and right_hip.y > right_knee.y:
            action = "Sentado"
        elif abs(left_hip.y - right_hip.y) < 0.05 and abs(left_knee.y - right_knee.y) < 0.05:
            action = "Caminando"
        else:
            action = "Accion no reconocida"

        cv2.putText(frame, f"AcciÃ³n: {action}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)

    cv2.imshow("Reconocimiento de Postura", frame)
    if cv2.waitKey(1) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()
```

---

## ğŸ“Š Resultados Visuales

Al ejecutar el proyecto, la cÃ¡mara detecta la postura del usuario en tiempo real y muestra en pantalla la acciÃ³n reconocida (por ejemplo, "Levantando brazos", "Sentado", "Caminando") junto con los puntos clave del cuerpo.

![python_EHUY6fzo3E.gif](resultado/python_EHUY6fzo3E.gif)

---

## ğŸ§© Prompts Usados

```text
"Â¿CÃ³mo detectar si una persona estÃ¡ levantando los brazos usando MediaPipe?"
"Â¿CÃ³mo clasificar posturas bÃ¡sicas con landmarks de pose en Python?"
"Â¿CÃ³mo mostrar el nombre de la acciÃ³n detectada sobre el video en OpenCV?"
```

---

## ğŸ’¬ ReflexiÃ³n Final

Este taller permitiÃ³ aplicar de manera prÃ¡ctica el reconocimiento de posturas humanas usando visiÃ³n por computadora. La integraciÃ³n de MediaPipe y OpenCV facilitÃ³ la detecciÃ³n y visualizaciÃ³n de landmarks, mientras que la lÃ³gica condicional permitiÃ³ clasificar acciones bÃ¡sicas de forma sencilla. El mayor reto fue definir reglas robustas para distinguir entre posturas similares y asegurar la respuesta en tiempo real.

Para futuros proyectos, serÃ­a interesante ampliar el sistema para reconocer mÃ¡s acciones, mejorar la robustez ante diferentes posiciones de cÃ¡mara y explorar la integraciÃ³n con retroalimentaciÃ³n auditiva o control de interfaces.

---

## âœ… Checklist de Entrega

- [x] Carpeta `2025-06-24_taller_reconocimiento_postura_mediapipe`
- [x] CÃ³digo limpio y funcional
- [x] GIF incluido con nombre descriptivo
- [x] README completo y claro
- [x] Commits descriptivos en inglÃ©s

---
