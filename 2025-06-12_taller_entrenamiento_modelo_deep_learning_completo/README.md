# ğŸ§ª Taller - Entrenamiento y Fine-Tuning de un Modelo Deep Learning en MNIST

## ğŸ—“ï¸ Fecha

2025-06-12

---

## ğŸ¯ Objetivo del Taller

Entrenar un modelo de deep learning sobre el dataset MNIST, aplicar tÃ©cnicas de validaciÃ³n y realizar fine-tuning utilizando un modelo preentrenado. Analizar el impacto del fine-tuning y comparar los resultados obtenidos.

---

## ğŸ§  Conceptos Aprendidos

* Carga y preprocesamiento de datos con PyTorch.
* DefiniciÃ³n y entrenamiento de redes neuronales simples.
* ValidaciÃ³n cruzada (K-Fold) y su importancia.
* Fine-tuning de modelos preentrenados (ResNet18).
* EvaluaciÃ³n de modelos: curvas de pÃ©rdida, matriz de confusiÃ³n y mÃ©tricas de desempeÃ±o.
* ComparaciÃ³n de resultados entre modelos desde cero y modelos ajustados.

---

## ğŸ› ï¸ Herramientas y Entornos

* Python 3.x
* PyTorch y torchvision
* Scikit-learn
* Matplotlib y Seaborn
* Pandas

---

## ğŸ“ Estructura del Proyecto

```
2025-06-12_taller_entrenamiento_modelo_deep_learning_completo/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ MNIST/
â”œâ”€â”€ modelos/
â”‚   â””â”€â”€ modelo_final.pth
â”œâ”€â”€ resultados/
â”‚   â”œâ”€â”€ curva_loss.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ comparacion_metrics.csv
â”‚   â””â”€â”€ ejemplo_mnist.png
â””â”€â”€ python/
    â””â”€â”€ entrenamiento_modelo.py
```

---

## ğŸ’¡ ImplementaciÃ³n Destacada

### ğŸ”¹ Carga y visualizaciÃ³n del dataset MNIST

```python
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])
train_data = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)
test_data = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)
```
*Se utiliza el dataset MNIST, que contiene imÃ¡genes de dÃ­gitos manuscritos (28x28 pÃ­xeles, escala de grises).*

### ğŸ”¹ VisualizaciÃ³n de un ejemplo

```python
def visualizar_ejemplo(dataset):
    image, label = dataset[0]
    plt.imshow(image.squeeze(), cmap="gray")
    plt.title(f"Etiqueta: {label}")
    plt.savefig(os.path.join(resultados_dir, "ejemplo_mnist.png"))
    plt.close()
visualizar_ejemplo(train_data)
```
*Se guarda una imagen de ejemplo para inspecciÃ³n visual.*

### ğŸ”¹ DefiniciÃ³n del modelo simple

```python
class SimpleNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.net = nn.Sequential(
            nn.Flatten(),
            nn.Linear(28*28, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 10)
        )
    def forward(self, x):
        return self.net(x)
```
*Red neuronal simple con dos capas ocultas y dropout para regularizaciÃ³n.*

### ğŸ”¹ Entrenamiento y validaciÃ³n

```python
def entrenar_modelo(model, train_loader, val_loader, epochs=10, lr=0.001, device="cpu"):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=lr)
    train_losses, val_losses, val_accuracies = [], [], []
    for epoch in range(epochs):
        # Entrenamiento y validaciÃ³n...
    return train_losses, val_losses, val_accuracies
```
*FunciÃ³n genÃ©rica para entrenar y validar el modelo, guardando las curvas de pÃ©rdida.*

### ğŸ”¹ Fine-tuning con modelo preentrenado

```python
model_ft = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)
for param in model_ft.parameters():
    param.requires_grad = False
model_ft.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)
num_ftrs = model_ft.fc.in_features
model_ft.fc = nn.Linear(num_ftrs, 10)
```
*Se adapta ResNet18 para imÃ¡genes de un canal y se ajusta solo la capa final para el fine-tuning.*

### ğŸ”¹ ComparaciÃ³n de mÃ©tricas

```python
metrics = {
    "Modelo": ["SimpleNN", "ResNet18 (fine-tuning)"],
    "Accuracy": [np.mean(kfold_metrics), np.mean(ft_val_accuracies)],
    "Precision": [...],
    "Recall": [...]
}
df_metrics = pd.DataFrame(metrics)
df_metrics.to_csv(os.path.join(resultados_dir, "comparacion_metrics.csv"), index=False)
```
*Se guardan las mÃ©tricas de ambos modelos para comparaciÃ³n.*

---

## ğŸ“Š Resultados Visuales

* Ejemplo de imagen MNIST:  
  ![ejemplo_mnist.png](resultados/ejemplo_mnist.png)
* Curva de pÃ©rdida durante el entrenamiento:  
  ![curva_loss.png](resultados/curva_loss.png)
* Matriz de confusiÃ³n del modelo simple:  
  ![confusion_matrix.png](resultados/confusion_matrix.png)
* ComparaciÃ³n de mÃ©tricas (accuracy, precision, recall):  
  Archivo: `comparacion_metrics.csv`

---

## ğŸ” Prompts Utilizados

* "cÃ³mo hacer fine-tuning en PyTorch con ResNet18"
* "validaciÃ³n cruzada k-fold en PyTorch"
* "cÃ³mo guardar y cargar modelos en PyTorch"
* "cÃ³mo graficar matriz de confusiÃ³n y curvas de pÃ©rdida"
* "adaptar ResNet para imÃ¡genes de un canal"

---

## ğŸ’¬ ReflexiÃ³n Final

El fine-tuning permite aprovechar el conocimiento previo de modelos grandes, pero su efectividad depende de la similitud entre el dataset original y el nuevo. En este caso, el modelo simple entrenado desde cero superÃ³ al modelo ajustado (ResNet18), probablemente porque MNIST es un dataset muy diferente a los datos originales de ResNet (ImageNet, imÃ¡genes a color y de mayor resoluciÃ³n). La validaciÃ³n cruzada K-Fold fue especialmente Ãºtil para estimar la variabilidad del desempeÃ±o y evitar sobreajuste. En resumen, el fine-tuning no siempre garantiza mejores resultados, pero es una herramienta poderosa cuando se usa en contextos adecuados. 